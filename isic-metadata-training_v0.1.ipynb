{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Data Preparation","metadata":{}},{"cell_type":"markdown","source":"Clustering, Dimensionality Reduction, then Both, with clustering evaluation\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.decomposition import PCA, FastICA\nfrom sklearn.random_projection import GaussianRandomProjection\nfrom sklearn.manifold import TSNE\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.impute import SimpleImputer\nimport joblib\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# Load the metadata\nmetadata = pd.read_csv(\"/kaggle/input/isic-2024-challenge/train-metadata.csv\", low_memory=False)\n\n# Use only 5% of the data for now\nmetadata_sampled = metadata.sample(frac=0.05, random_state=42)\n\n# Preprocess the metadata\ndef preprocess_metadata(metadata, is_train=True):\n    # Fill missing values\n    metadata = metadata.fillna(metadata.median(numeric_only=True))\n    metadata = metadata.fillna('Unknown')\n\n    # Columns specific to training data\n    train_only_cols = ['target', 'lesion_id', 'iddx_full', 'iddx_1', 'iddx_2', 'iddx_3', 'iddx_4', 'iddx_5']\n    drop_cols = ['isic_id', 'patient_id']\n\n    # Drop columns specific to training data\n    if is_train:\n        drop_cols.extend(train_only_cols)\n    \n    metadata = metadata.drop(columns=[col for col in drop_cols if col in metadata.columns])\n\n    # Define categorical and numerical columns\n    categorical_cols = metadata.select_dtypes(include=['object']).columns.tolist()\n    numerical_cols = metadata.select_dtypes(include=['number']).columns.tolist()\n\n    # One-hot encode categorical variables and scale numerical variables\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num_imputer', SimpleImputer(strategy='mean'), numerical_cols),\n            ('num_scaler', StandardScaler(), numerical_cols),\n            ('cat', OneHotEncoder(sparse=False, handle_unknown='ignore'), categorical_cols)])\n\n    if is_train:\n        return preprocessor.fit(metadata)\n    else:\n        return preprocessor.transform(metadata)\n\n# Preprocess the metadata\npreprocessor = preprocess_metadata(metadata_sampled, is_train=True)\nmetadata_processed = preprocessor.transform(metadata_sampled)\ntarget = metadata_sampled['target']\n\n# Save the preprocessor\njoblib.dump(preprocessor, 'preprocessor.pkl')\n\n# Dimensionality reduction and clustering functions\ndef apply_dimensionality_reduction(X, method, n_components=2):\n    if method == 'PCA':\n        dr = PCA(n_components=n_components)\n    elif method == 'ICA':\n        dr = FastICA(n_components=n_components)\n    elif method == 'RP':\n        dr = GaussianRandomProjection(n_components=n_components)\n    elif method == 't-SNE':\n        perplexity = min(30, X.shape[0] - 1)\n        dr = TSNE(n_components=n_components, perplexity=perplexity)\n    else:\n        raise ValueError(f\"Unknown method: {method}\")\n    X_reduced = dr.fit_transform(X)\n    return X_reduced\n\ndef apply_clustering(X, method, n_clusters=2):\n    if method == 'KMeans':\n        model = KMeans(n_clusters=n_clusters, random_state=42)\n    elif method == 'GMM':\n        model = GaussianMixture(n_components=n_clusters, random_state=42)\n    else:\n        raise ValueError(f\"Unknown clustering method: {method}\")\n    clusters = model.fit_predict(X)\n    return clusters\n\n# Plotting functions\ndef plot_visualization_grid(ax, method, X, y=None):\n    X_reduced = apply_dimensionality_reduction(X, method)\n    if y is not None:\n        ax.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y, cmap='viridis', edgecolor='k')\n    else:\n        ax.scatter(X_reduced[:, 0], X_reduced[:, 1], cmap='viridis', edgecolor='k')\n    ax.set_title(f\"{method} Visualization\")\n\ndef plot_clustering_grid(ax, method, X):\n    clusters = apply_clustering(X, method)\n    silhouette_avg = silhouette_score(X, clusters)\n    ax.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', edgecolor='k')\n    ax.set_title(f\"{method} Clustering (Silhouette: {silhouette_avg:.2f})\")\n\ndef plot_dim_red_then_clustering(ax, dim_red_method, cluster_method, X):\n    X_reduced = apply_dimensionality_reduction(X, dim_red_method)\n    clusters = apply_clustering(X_reduced, cluster_method)\n    silhouette_avg = silhouette_score(X_reduced, clusters)\n    ax.scatter(X_reduced[:, 0], X_reduced[:, 1], c=clusters, cmap='viridis', edgecolor='k')\n    ax.set_title(f\"{dim_red_method} + {cluster_method} (Silhouette: {silhouette_avg:.2f})\")\n\n# Plot in grid\ndef plot_in_grid(methods, plot_function, rows, cols, title_prefix, X, y=None, is_clustering=False):\n    fig, axs = plt.subplots(rows, cols, figsize=(20, 10))\n    axs = axs.flatten()\n    for i, method in enumerate(methods):\n        if is_clustering:\n            plot_function(axs[i], method, X)\n        else:\n            plot_function(axs[i], method, X, y)\n    for ax in axs[len(methods):]:\n        fig.delaxes(ax)\n    plt.tight_layout()\n    plt.suptitle(f\"{title_prefix}\", y=1.02, fontsize=16)\n    plt.show()\n\n# Dimensionality reduction then clustering\ndef plot_dim_red_then_clustering_grid(dim_red_methods, cluster_methods, X):\n    fig, axs = plt.subplots(len(dim_red_methods), len(cluster_methods), figsize=(20, 5 * len(dim_red_methods)))\n    for i, dim_red_method in enumerate(dim_red_methods):\n        for j, cluster_method in enumerate(cluster_methods):\n            plot_dim_red_then_clustering(axs[i, j], dim_red_method, cluster_method, X)\n    plt.tight_layout()\n    plt.suptitle(\"Dim. Reduction + Clustering\", y=1.02, fontsize=16)\n    plt.show()\n\n# Apply and plot\nclustering_methods = ['KMeans', 'GMM']\ndim_red_methods = ['PCA', 'ICA', 'RP', 't-SNE']\n\n# Step 1: Run clustering, then visualize data\nplot_in_grid(clustering_methods, plot_clustering_grid, 1, 2, \"Clustering Methods\", metadata_processed, y=None, is_clustering=True)\n\n# Step 2: Run dim. red. then visualize data\nplot_in_grid(dim_red_methods, plot_visualization_grid, 2, 2, \"Dim. Red. Methods\", metadata_processed, y=None, is_clustering=False)\n\n# Step 3: Run dim. red., then clustering, then visualize data\nplot_dim_red_then_clustering_grid(dim_red_methods, clustering_methods, metadata_processed)\n\n# Metrics evaluation functions\ndef evaluate_pca(X):\n    pca = PCA()\n    pca.fit(X)\n    explained_variance = pca.explained_variance_ratio_\n    return explained_variance\n\ndef evaluate_ica(X):\n    ica = FastICA()\n    ica.fit(X)\n    kurtosis = pd.DataFrame(ica.components_).kurt(axis=1).abs().values\n    return kurtosis\n\ndef evaluate_rp(X):\n    rp = GaussianRandomProjection(n_components=50)\n    X_projected = rp.fit_transform(X)\n    X_reconstructed = np.dot(X_projected, np.linalg.pinv(rp.components_.T))\n    reconstruction_error = np.mean((X - X_reconstructed) ** 2)\n    return reconstruction_error\n\ndef tabulate_metrics(X):\n    pca_var = evaluate_pca(X)\n    ica_kurt = evaluate_ica(X)\n    rp_err = evaluate_rp(X)\n    \n    print(\"PCA Explained Variance Ratio:\", pca_var)\n    print(\"ICA Mean Kurtosis:\", ica_kurt)\n    print(\"RP Reconstruction Error:\", rp_err)\n\n# Tabulate metrics\ntabulate_metrics(metadata_processed)\n\n# Prepare data for the model\nX_train, X_val, y_train, y_val = train_test_split(metadata_processed, target, test_size=0.2, random_state=42)\n\n# Define and train the MLP\nmlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\nmlp.fit(X_train, y_train)\n\n# Save the trained model and the dimensionality reduction method used\njoblib.dump(mlp, 'mlp_model.pkl')\njoblib.dump('PCA', 'dim_red_method.pkl')  # Example, you should save the actual method you used\n\n# Predict and evaluate\ny_pred = mlp.predict_proba(X_val)[:, 1]\nroc_auc = roc_auc_score(y_val, y_pred)\n\nprint(f\"ROC AUC Score: {roc_auc}\")\n\n# Plot ROC Curve\nfpr, tpr, _ = roc_curve(y_val, y_pred)\nplt.figure()\nplt.plot(fpr, tpr, label=f'MLP (area = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='navy', linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n# Plot Learning Curves\ndef plot_learning_curve(estimator, title, X, y, cv=None, n_jobs=None, train_sizes=np.linspace(0.1, 1.0, 5), scoring='roc_auc'):\n    plt.figure()\n    plt.title(title)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\" if scoring == 'roc_auc' else \"Error rate\")\n    \n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring=scoring\n    )\n    \n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    plt.grid()\n    \n    if scoring == 'roc_auc':\n        plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                         train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n        plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                         test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n        plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n        plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n    else:\n        train_error = 1 - train_scores_mean\n        test_error = 1 - test_scores_mean\n        plt.fill_between(train_sizes, train_error - train_scores_std,\n                         train_error + train_scores_std, alpha=0.1, color=\"r\")\n        plt.fill_between(train_sizes, test_error - test_scores_std,\n                         test_error + test_scores_std, alpha=0.1, color=\"g\")\n        plt.plot(train_sizes, train_error, 'o-', color=\"r\", label=\"Training error\")\n        plt.plot(train_sizes, test_error, 'o-', color=\"g\", label=\"Cross-validation error\")\n\n    plt.legend(loc=\"best\")\n    return plt\n\n# Plot learning curve for ROC AUC\nplot_learning_curve(mlp, \"Learning Curve (ROC AUC) - MLP\", X_train, y_train, cv=5, scoring='roc_auc')\nplt.show()\n\n# Plot learning curve for error (1 - accuracy)\nplot_learning_curve(mlp, \"Learning Curve (Error) - MLP\", X_train, y_train, cv=5, scoring='accuracy')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T13:15:36.584762Z","iopub.execute_input":"2024-07-18T13:15:36.585167Z","iopub.status.idle":"2024-07-18T13:15:44.275770Z","shell.execute_reply.started":"2024-07-18T13:15:36.585137Z","shell.execute_reply":"2024-07-18T13:15:44.274057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Training and Evaluation","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import learning_curve\n\n# Define and train the MLP\nmlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\nmlp.fit(X_train, y_train)\n\n# Predict and evaluate\ny_pred = mlp.predict_proba(X_val)[:, 1]\nroc_auc = roc_auc_score(y_val, y_pred)\n\nprint(f\"ROC AUC Score: {roc_auc}\")\n\n# Plot ROC Curve\nfpr, tpr, _ = roc_curve(y_val, y_pred)\nplt.figure()\nplt.plot(fpr, tpr, label=f'MLP (area = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='navy', linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n# Plot Learning Curves\ndef plot_learning_curve(estimator, title, X, y, cv=None, n_jobs=None, train_sizes=np.linspace(0.1, 1.0, 5), scoring='roc_auc'):\n    plt.figure()\n    plt.title(title)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\" if scoring == 'roc_auc' else \"Error rate\")\n    \n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring=scoring\n    )\n    \n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    plt.grid()\n    \n    if scoring == 'roc_auc':\n        plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                         train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n        plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                         test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n        plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n        plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n    else:\n        train_error = 1 - train_scores_mean\n        test_error = 1 - test_scores_mean\n        plt.fill_between(train_sizes, train_error - train_scores_std,\n                         train_error + train_scores_std, alpha=0.1, color=\"r\")\n        plt.fill_between(train_sizes, test_error - test_scores_std,\n                         test_error + test_scores_std, alpha=0.1, color=\"g\")\n        plt.plot(train_sizes, train_error, 'o-', color=\"r\", label=\"Training error\")\n        plt.plot(train_sizes, test_error, 'o-', color=\"g\", label=\"Cross-validation error\")\n\n    plt.legend(loc=\"best\")\n    return plt\n\n# Plot learning curve for ROC AUC\nplot_learning_curve(mlp, \"Learning Curve (ROC AUC) - MLP\", X_train, y_train, cv=5, scoring='roc_auc')\nplt.show()\n\n# Plot learning curve for error (1 - accuracy)\nplot_learning_curve(mlp, \"Learning Curve (Error) - MLP\", X_train, y_train, cv=5, scoring='accuracy')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T13:00:24.320951Z","iopub.execute_input":"2024-07-18T13:00:24.321412Z","iopub.status.idle":"2024-07-18T13:02:35.342707Z","shell.execute_reply.started":"2024-07-18T13:00:24.321372Z","shell.execute_reply":"2024-07-18T13:02:35.341515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference Test","metadata":{}}]}